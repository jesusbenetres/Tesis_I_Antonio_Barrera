\chapter{PLANTEAMIENTO DEL PROBLEMA}
\section{Descripción de la Realidad Problemática}

En la actualidad, el uso de tecnologías avanzadas, como la inteligencia artificial (IA), ha permitido la creación de contenido multimedia falsificado conocido como deepfake. Este contenido incluye videos, imágenes y, más recientemente, audios. Los deepfakes de audio han adquirido una relevancia particular debido a su capacidad para imitar voces humanas con una precisión asombrosa, lo que ha desencadenado una serie de problemas relacionados con la seguridad y la confianza en las comunicaciones digitales \parencite{heidari2023}. Esta tecnología ha comenzado a ser utilizada para fraudes y suplantación de identidad, presentando un desafío significativo para la detección de audios manipulados, especialmente en español, donde las herramientas actuales de detección no están adecuadamente adaptadas para capturar las particularidades del idioma.

En Perú, el fraude mediante deepfakes de audio ha mostrado un aumento considerable en los últimos años. Un informe de la Policía Nacional del Perú (PNP) revela que más de un millón de soles han sido robados mediante la clonación de voces utilizando IA. En estos fraudes, los delincuentes suelen imitar la voz de familiares o amigos para solicitar dinero en situaciones de emergencia falsas, lo que resulta en un engaño muy difícil de detectar por las víctimas \parencite{rojas2023}. Este incremento de fraudes plantea un problema general relacionado con la incapacidad de las herramientas actuales para detectar audios falsificados, lo que facilita la comisión de delitos en el ámbito digital.

Uno de los problemas específicos más críticos es la falta de un dataset en español que contemple variaciones regionales y voces manipuladas para entrenar modelos de redes neuronales profundas. La mayoría de los avances en la detección de deepfakes de audio se han centrado en el inglés, lo que genera una brecha importante en la capacidad de los modelos para adaptarse a las características del habla en español, que presenta variaciones significativas en términos de patrones de voz, frecuencia fundamental y ritmo del habla \parencite{heidari2023}. Esta falta de datos específicos en español dificulta la construcción de modelos robustos que puedan detectar deepfakes con precisión en este idioma.

Otro problema específico está relacionado con las limitaciones técnicas de las herramientas actuales para analizar variables clave como el tono de voz, timbre de voz y formantes. Los audios falsificados mediante deepfakes logran imitar estas características acústicas de manera casi perfecta, lo que confunde tanto a los sistemas de detección como a las personas. En particular, los deepfakes en español plantean desafíos únicos debido a las diferencias fonéticas con otros idiomas, lo que complica aún más la detección efectiva de manipulaciones \parencite{amesquita2023}.

Un tercer problema específico se refiere al uso de deepfakes de audio en fraudes por suplantación de identidad en Perú, donde los delincuentes utilizan esta tecnología para hacer pasar sus voces por las de familiares o colegas en situaciones de emergencia o negociación. Estos fraudes, que afectan tanto a individuos como a empresas, se ven agravados por la dificultad de las técnicas actuales para analizar características como la prosodia, articulación, transiciones entre fonemas y ruidos de fondo. Estos factores son críticos para la identificación precisa de audios falsificados, ya que los deepfakes no siempre logran replicar con fidelidad estos aspectos del habla humana, pero los sistemas de detección existentes no están optimizados para capturarlos \parencite{chen2024}.

A nivel global, se ha documentado un incremento en el uso de deepfakes para cometer fraudes, con pérdidas millonarias en varios países. En Hong Kong, por ejemplo, se reportó un caso en el que un trabajador fue engañado mediante una videollamada con deepfakes de varios miembros de la junta directiva de su empresa, lo que resultó en un fraude de 25 millones de dólares \parencite{chen2024}. Este tipo de casos destaca la urgencia de desarrollar soluciones tecnológicas más efectivas que permitan la detección de deepfakes de audio en español, donde las herramientas actuales siguen siendo insuficientes.

En el contexto peruano, la proliferación de fraudes basados en deepfakes de audio no solo afecta a los individuos, sino también a figuras públicas. Un caso reciente involucró a la presidenta Dina Boluarte, cuya voz fue manipulada mediante IA para hacer parecer que promovía una inversión fraudulenta, lo que generó confusión entre el público y demostró el poder de esta tecnología para influir en la opinión pública y causar daño reputacional \parencite{amesquita2023}.

Por todo lo anterior, es evidente que la detección de deepfakes de audio en español requiere un enfoque más sofisticado. El desarrollo de modelos basados en redes neuronales profundas que puedan analizar variables acústicas clave, como el tono de voz, timbre de voz, patrones de voz, frecuencia fundamental, duración y ritmo del habla, formantes, nivel de energía del habla, ruidos de fondo, prosodia, articulación y transiciones entre fonemas, es esencial para mitigar el impacto de los fraudes por deepfakes en Perú. Estas variables juegan un papel fundamental en la autenticidad del habla y pueden proporcionar pistas valiosas para identificar audios manipulados. Sin embargo, la falta de modelos especializados en español y la escasez de datasets específicos siguen siendo los principales obstáculos para lograr una detección precisa y confiable.

\section{Formulación del Problema}

\subsection{Problema General}
\newcommand{\ProblemaGeneral}{
	El incremento del fraude en Perú mediante el uso de tecnologías deepfake de audio ha evidenciado la falta de herramientas adecuadas para detectar estos fraudes, especialmente en español. Las técnicas actuales no logran identificar eficazmente las características acústicas del español, como el tono de voz, timbre de voz, patrones de voz, frecuencia fundamental (pitch), duración y ritmo del habla, formantes, nivel de energía del habla (intensidad), ruidos de fondo, prosodia, articulación y transiciones entre fonemas, lo que facilita la suplantación de identidad y el fraude en las comunicaciones personales y empresariales. 
}
\ProblemaGeneral
\subsection{Problemas Espec\'{i}ficos}
\newcommand{\Pbone}{
La falta de un dataset en español que incluya variaciones regionales y voces manipuladas dificulta el entrenamiento de modelos de redes neuronales profundas para detectar deepfakes de audio en español, debido a las diferencias en patrones de voz, frecuencia fundamental (pitch) y ritmo del habla.
}
\newcommand{\Pbtwo}{
Las técnicas actuales no logran detectar las variaciones en el tono de voz, timbre de voz y formantes en audios en español, lo que disminuye la precisión en la identificación de audios manipulados.
}
\newcommand{\Pbthree}{
Los fraudes por suplantación de identidad mediante deepfakes de audio en Perú son difíciles de detectar con las técnicas actuales debido a la falta de análisis de prosodia, articulación, transiciones entre fonemas y ruidos de fondo, lo que incrementa el riesgo de fraude.
}


\begin{itemize}
	\item \Pbone
	\item \Pbtwo
	\item \Pbthree

\end{itemize}

\section{Objetivos de la Investigación}
Para la formulación de los objetivos de la presente investigación se elaboró un «árbol de objetivos» (véase Anexo 2) 
\subsection{Objetivo General}
\newcommand{\ObjetivoGeneral}{
Desarrollar un modelo basado en redes neuronales profundas que permita detectar deepfakes de audio en español mediante el análisis de variables clave como tono de voz, timbre de voz, patrones de voz, frecuencia fundamental, duración y ritmo del habla, formantes, nivel de energía del habla, ruidos de fondo, prosodia, articulación y transiciones entre fonemas, mejorando la precisión en la identificación de audios manipulados para mitigar fraudes por suplantación de identidad en Perú.
}
\ObjetivoGeneral
\subsection{Objetivos Espec\'{i}ficos}
\newcommand{\Objone}{
Desarrollar un dataset específico en español, con variaciones regionales y voces manipuladas, para entrenar un modelo de redes neuronales profundas que detecte deepfakes de audio
}
\newcommand{\Objtwo}{
Implementar un modelo de redes neuronales profundas que analice el tono de voz, timbre de voz y formantes para mejorar la precisión en la detección de deepfakes de audio en español.
}
\newcommand{\Objthree}{
Evaluar la eficacia del modelo de redes neuronales profundas en la detección de deepfakes de audio en contextos de fraude por suplantación de identidad en Perú, considerando prosodia, articulación, transiciones entre fonemas y ruidos de fondo.
}

\begin{itemize}
	\item {\Objone}
	\item {\Objtwo}
	\item {\Objthree}
\end{itemize}

\section{Justificación de la Investigación}

\subsection{Teórica}
Desde una perspectiva teórica, esta investigación aporta al campo de la inteligencia artificial y el procesamiento de señales de audio, profundizando en el análisis y la detección de deepfakes mediante el uso de redes neuronales profundas. Actualmente, la mayoría de los avances en detección de deepfakes de audio se han centrado en el inglés, lo que deja una brecha significativa en el desarrollo de modelos efectivos para el idioma español \parencite{heidari2023}. Esta investigación se propone cubrir esa brecha, explorando cómo las características fonéticas del español (como la frecuencia fundamental, prosodia, formantes, y ruidos de fondo) pueden ser integradas en modelos de detección de audio. El desarrollo teórico de esta investigación se basa en los principios del aprendizaje profundo (deep learning) y su aplicación al análisis acústico, ampliando las bases teóricas sobre cómo los modelos de redes neuronales pueden ser adaptados para trabajar con diferentes idiomas y contextos culturales. Además, al enfocarse en las características específicas del español, esta investigación contribuye al desarrollo de datasets y herramientas especializadas que pueden ser utilizados en investigaciones futuras, tanto en el ámbito académico como en la industria 

\subsection{Práctica}
La investigación sobre la detección de audios deepfake en español utilizando redes neuronales profundas es esencial en el contexto actual de seguridad digital, especialmente en Perú, donde se ha registrado un incremento preocupante de fraudes utilizando esta tecnología. Las suplantaciones de identidad mediante la clonación de voces, como lo demuestran los más de 94 casos de estafa reportados en 2023, con pérdidas superiores a un millón de soles \parencite{rojas2023}, subrayan la vulnerabilidad de los sistemas actuales de detección. A nivel práctico, esta investigación tiene un impacto directo en la mitigación de estos fraudes. Al desarrollar modelos adaptados a las características específicas del español, como el tono de voz, timbre de voz y patrones de voz, se busca ofrecer soluciones tecnológicas robustas que permitan la identificación temprana de audios manipulados, reduciendo así los riesgos financieros y personales para los usuarios. Además, instituciones gubernamentales y empresas peruanas podrán aplicar los resultados de esta investigación para mejorar sus sistemas de seguridad y protección contra la suplantación de identidad, brindando un entorno más seguro para las comunicaciones digitales 

\subsection{Metodológica}

La elección de redes neuronales profundas como metodología principal para la detección de audios deepfake se fundamenta en su capacidad superior para procesar y analizar grandes volúmenes de datos complejos, como las características acústicas de la voz humana. Las redes neuronales profundas permiten extraer automáticamente patrones y características de los datos de audio, como el tono de voz, timbre de voz, patrones de voz, frecuencia fundamental, prosodia, entre otros, lo que las convierte en una herramienta eficaz para abordar la naturaleza compleja de los deepfakes \parencite{heidari2023}. Además, estas redes tienen la capacidad de aprender de manera no supervisada y de adaptarse a las particularidades del idioma español, lo que es crucial dado que la mayoría de los avances en detección de deepfakes se han desarrollado en inglés.

Metodológicamente, el enfoque basado en redes neuronales profundas es ideal porque permite trabajar con un conjunto de variables independientes que incluyen tanto aspectos del habla (como la articulación y las transiciones entre fonemas) como la calidad del entorno de grabación (como los ruidos de fondo). La capacidad de estas redes para analizar simultáneamente múltiples dimensiones del audio y encontrar patrones que escapan a la detección humana o métodos tradicionales es fundamental para enfrentar la creciente sofisticación de los fraudes con deepfakes de audio \parencite{ji2024}.

Otra razón metodológica clave es que el uso de redes neuronales profundas facilita la construcción de modelos predictivos que mejoran su precisión con el tiempo a medida que se entrenan con más datos. Esta flexibilidad es esencial, ya que el desarrollo de datasets específicos en español, con variaciones regionales y diferentes características de la voz, permitirá entrenar a los modelos de manera más eficaz para identificar manipulaciones en contextos reales \parencite{rojas2023}. Por lo tanto, la metodología propuesta no solo es adecuada para la detección precisa de deepfakes de audio, sino que también es escalable y adaptable a futuros avances en la tecnología de falsificación de audios. 

\section{Delimitación del Estudio}

\subsection{Espacial}
La presente investigación se desarrollará principalmente en el contexto de Perú, donde se ha identificado un incremento significativo en los fraudes utilizando tecnologías de deepfake de audio. El enfoque estará en analizar audios en español y las variaciones regionales del idioma dentro del país, ya que las características fonéticas del español peruano presentan particularidades que deben ser consideradas al desarrollar modelos de detección de deepfakes. Además, la aplicación de los resultados será relevante para instituciones gubernamentales, empresas y usuarios individuales en Perú, que enfrentan amenazas crecientes en el ámbito de la seguridad digital.

\subsection{Temporal}
El estudio abarcará el periodo 2023-2024, un lapso en el cual se han observado incrementos importantes en el uso fraudulento de deepfakes de audio tanto a nivel global como en Perú. La recolección de datos, construcción del dataset y desarrollo del modelo de redes neuronales profundas se llevarán a cabo en este periodo. Asimismo, se buscará analizar los fraudes recientes, reportados en los últimos dos años, para entender los patrones y tendencias de los ataques con deepfakes en audio 

\subsection{Conceptual}
La investigación se centra en la detección de deepfakes de audio mediante el uso de redes neuronales profundas. Los conceptos clave abordados incluyen las características acústicas del habla, como el tono de voz, timbre de voz, frecuencia fundamental (pitch), duración y ritmo del habla, prosodia, formantes, articulación y ruidos de fondo, entre otros. Además, se explorará cómo estas variables son manipuladas por tecnologías de deepfake para suplantar identidades. El estudio también se delimita a la detección en español, debido a las diferencias fonéticas y lingüísticas entre este idioma y otros en los que se ha enfocado la investigación previa, como el inglés. 

\section{Hipótesis}

\subsection{Hipótesis General}
\newcommand{\HipotesisGeneral}{
El uso de un modelo basado en redes neuronales profundas que analice las variables acústicas clave como tono de voz, timbre de voz, patrones de voz, frecuencia fundamental, duración y ritmo del habla, formantes, nivel de energía del habla, ruidos de fondo, prosodia, articulación y transiciones entre fonemas mejora significativamente la precisión en la detección de deepfakes de audio en español, reduciendo el riesgo de fraudes por suplantación de identidad en Perú.
}
\HipotesisGeneral
\subsection{Hipótesis Específicas}
\newcommand{\Hone}{
La creación de un dataset en español que incluya variaciones regionales y voces manipuladas mejorará significativamente la capacidad de las redes neuronales profundas para detectar deepfakes de audio en este idioma
}
\newcommand{\Htwo}{
El análisis del tono de voz, timbre de voz y formantes mediante redes neuronales profundas aumentará la precisión en la detección de deepfakes de audio en español.
}
\newcommand{\Hthree}{
El modelo de redes neuronales profundas será más efectivo en la detección de deepfakes en contextos de fraude en Perú al incluir el análisis de prosodia, articulación, transiciones entre fonemas y ruidos de fondo, en comparación con las técnicas actuales.	
}

\begin{itemize}
	\item \Hone
	\item \Htwo
	\item \Hthree
\end{itemize}

\subsection{Matriz de Consistencia}
A continuación se presenta la matriz de consistencia elaborada para la presente investigación (véase Anexo \ref{1:table}).

